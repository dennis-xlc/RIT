#dt: S8/S16/S32/U8/U16/U32
VABA.<dt> <Qd>, <Qn>, <Qm>
VABA.<dt> <Dd>, <Dn>, <Dm>
VABAL.<dt> <Qd>, <Dn>, <Dm>

#dt: S8/S16/S32/U8/U16/U32
VABD.<dt> <Qd>, <Qn>, <Qm>
VABD.<dt> <Dd>, <Dn>, <Dm>
VABDL.<dt> <Qd>, <Dn>, <Dm>

VABD<c>.F32 <Qd>, <Qn>, <Qm>
VABD<c>.F32 <Dd>, <Dn>, <Dm>

#dt: S8/S16/S32/F32
VABS.<dt> <Qd>, <Qm>
VABS.<dt> <Dd>, <Dm>

//VABS.F64 <Dd>, <Dm>
//VABS.F32 <Sd>, <Sm>

VACGE.F32 <Qd>, <Qn>, <Qm>
VACGE.F32 <Dd>, <Dn>, <Dm>
VACGT.F32 <Qd>, <Qn>, <Qm>
VACGT.F32 <Dd>, <Dn>, <Dm>

#dt: I8/I16/I32/I64
VADD.<dt> <Qd>, <Qn>, <Qm>
VADD.<dt> <Dd>, <Dn>, <Dm>

VADD.F32 <Qd>, <Qn>, <Qm>
VADD.F32 <Dd>, <Dn>, <Dm>

//VADD<c>.F64 <Dd>, <Dn>, <Dm>
//VADD<c>.F32 <Sd>, <Sn>, <Sm>

#dt: I16/I32/I64 
VADDHN.<dt> <Dd>, <Qn>, <Qm>

#dt: S8/S16/S32/U8/U16/U32
VADDL.<dt> <Qd>, <Dn>, <Dm>
VADDW.<dt> <Qd>, <Qn>, <Dm>

VAND <Qd>, <Qn>, <Qm>
VAND <Dd>, <Dn>, <Dm>

#dt: I16/I32
VBIC.<dt> <Qd>, #<mimm>
VBIC.<dt> <Dd>, #<mimm>

VBIC <Qd>, <Qn>, <Qm>
VBIC <Dd>, <Dn>, <Dm>

VBIF <Qd>, <Qn>, <Qm>
VBIF <Dd>, <Dn>, <Dm>
VBIT <Qd>, <Qn>, <Qm>
VBIT <Dd>, <Dn>, <Dm>
VBSL <Qd>, <Qn>, <Qm>
VBSL <Dd>, <Dn>, <Dm>

#dt: I8/I16/I32
VCEQ.<dt> <Qd>, <Qn>, <Qm>
VCEQ.<dt> <Dd>, <Dn>, <Dm>

VCEQ.F32 <Qd>, <Qn>, <Qm>
VCEQ.F32 <Dd>, <Dn>, <Dm>

#dt: I8/I16/I32/F32
VCEQ.<dt> <Qd>, <Qm>, #0
VCEQ.<dt> <Dd>, <Dm>, #0

#dt: S8/S16/S32/U8/U16/U32
VCGE.<dt> <Qd>, <Qn>, <Qm>
VCGE.<dt> <Dd>, <Dn>, <Dm>

VCGE.F32 <Qd>, <Qn>, <Qm>
VCGE.F32 <Dd>, <Dn>, <Dm>

#dt: S8/S16/S32/F32
VCGE.<dt> <Qd>, <Qm>, #0
VCGE.<dt> <Dd>, <Dm>, #0

#dt: S8/S16/S32/U8/U16/U32
VCGT.<dt> <Qd>, <Qn>, <Qm>
VCGT.<dt> <Dd>, <Dn>, <Dm>

VCGT.F32 <Qd>, <Qn>, <Qm>
VCGT.F32 <Dd>, <Dn>, <Dm>

#dt: S8/S16/S32/F32
VCGT.<dt> <Qd>, <Qm>, #0
VCGT.<dt> <Dd>, <Dm>, #0

#dt: S8/S16/S32/F32
VCLE.<dt> <Qd>, <Qm>, #0
VCLE.<dt> <Dd>, <Dm>, #0

#dt: S8/S16/S32
VCLS.<dt> <Qd>, <Qm>
VCLS.<dt> <Dd>, <Dm>

#dt: S8/S16/S32/F32
VCLT.<dt> <Qd>, <Qm>, #0
VCLT.<dt> <Dd>, <Dm>, #0

#dt: I8/I16/I32
VCLZ.<dt> <Qd>, <Qm>
VCLZ.<dt> <Dd>, <Dm>

//VCMP<c>.F64 <Dd>, <Dm>
//VCMP<c>.F32 <Sd>, <Sm>
//VCMPE<c>.F64 <Dd>, <Dm>
//VCMPE<c>.F32 <Sd>, <Sm>

//VCMP<c>.F64 <Dd>, #0
//VCMP<c>.F32 <Sd>, #0
//VCMPE<c>.F64 <Dd>, #0
//VCMPE<c>.F32 <Sd>, #0

VCNT.8 <Qd>, <Qm>
VCNT.8 <Dd>, <Dm>

VCVT.S32.F32 <Qd>, <Qm>
VCVT.S32.F32 <Dd>, <Dm>
VCVT.U32.F32 <Qd>, <Qm>
VCVT.U32.F32 <Dd>, <Dm>
VCVT.F32.S32 <Qd>, <Qm>
VCVT.F32.S32 <Dd>, <Dm>
VCVT.F32.U32 <Qd>, <Qm>
VCVT.F32.U32 <Dd>, <Dm>

//VCVT<c>.S32.F64 <Sd>, <Dm>
//VCVT<c>.S32.F32 <Sd>, <Sm>
//VCVT<c>.U32.F64 <Sd>, <Dm>
//VCVT<c>.U32.F32 <Sd>, <Sm>
//VCVTR<c>.S32.F64 <Sd>, <Dm>
//VCVTR<c>.S32.F32 <Sd>, <Sm>
//VCVTR<c>.U32.F64 <Sd>, <Dm>
//VCVTR<c>.U32.F32 <Sd>, <Sm>
//VCVT<c>.F64.S32 <Dd>, <Sm>
//VCVT<c>.F64.U32 <Dd>, <Sm>
//VCVT<c>.F32.S32 <Sd>, <Sm>
//VCVT<c>.F32.U32 <Sd>, <Sm>

#dt: S32/U32
VCVT.<dt>.F32 <Qd>, <Qm>, #<imm5>+1
VCVT.<dt>.F32 <Dd>, <Dm>, #<imm5>+1
VCVT.F32.<dt> <Qd>, <Qm>, #<imm5>+1
VCVT.F32.<dt> <Dd>, <Dm>, #<imm5>+1

#dt: S16/U16/S32/U32
//VCVT<c>.<dt>.F64 <Dd>, <Dd>, #<fbits>
//VCVT<c>.<dt>.F32 <Sd>, <Sd>, #<fbits>
//VCVT<c>.F64.<dt> <Dd>, <Dd>, #<fbits>
//VCVT<c>.F32.<dt> <Sd>, <Sd>, #<fbits>

//VCVT<c>.F64.F32 <Dd>, <Sm>
//VCVT<c>.F32.F64 <Sd>, <Dm>

VCVT.F32.F16 <Qd>, <Dm>
VCVT.F16.F32 <Dd>, <Qm>

//VCVTB<c>.F32.F16 <Sd>, <Sm>
//VCVTB<c>.F16.F32 <Sd>, <Sm>
//VCVTT<c>.F32.F16 <Sd>, <Sm>
//VCVTT<c>.F16.F32 <Sd>, <Sm>

//VDIV<c>.F64 <Dd>, <Dn>, <Dm>
//VDIV<c>.F32 <Sd>, <Sn>, <Sm>

VDUP.8 <Qd>, <Dm>[<imm3>]
VDUP.8 <Dd>, <Dm>[<imm3>]
VDUP.16 <Qd>, <Dm>[<imm2>]
VDUP.16 <Dd>, <Dm>[<imm2>]
VDUP.32 <Qd>, <Dm>[<imm1>]
VDUP.32 <Dd>, <Dm>[<imm1>]

#size: 8/16/32
VDUP<c>.<size> <Qd>, <Rt>
VDUP<c>.<size> <Dd>, <Rt>

VEOR <Qd>, <Qn>, <Qm>
VEOR <Dd>, <Dn>, <Dm>

VEXT.8 <Qd>, <Qn>, <Qm>, #<imm4>
VEXT.8 <Dd>, <Dn>, <Dm>, #<imm3>

#dt: S8/S16/S32/U8/U16/U32
VHADD.<dt> <Qd>, <Qn>, <Qm>
VHADD.<dt> <Dd>, <Dn>, <Dm>
VHSUB.<dt> <Qd>, <Qn>, <Qm>
VHSUB.<dt> <Dd>, <Dn>, <Dm>


#dt: S8/S16/S32/U8/U16/U32
VMAX.<dt> <Qd>, <Qn>, <Qm>
VMAX.<dt> <Dd>, <Dn>, <Dm>
VMIN.<dt> <Qd>, <Qn>, <Qm>
VMIN.<dt> <Dd>, <Dn>, <Dm>

VMAX.F32 <Qd>, <Qn>, <Qm>
VMAX.F32 <Dd>, <Dn>, <Dm>
VMIN.F32 <Qd>, <Qn>, <Qm>
VMIN.F32 <Dd>, <Dn>, <Dm>

#dt: I8/I16/I32
VMLA.<dt> <Qd>, <Qn>, <Qm>
VMLA.<dt> <Dd>, <Dn>, <Dm>
VMLS.<dt> <Qd>, <Qn>, <Qm>
VMLS.<dt> <Dd>, <Dn>, <Dm>

#dt: S8/S16/S32/U8/U16/U32
VMLAL.<dt> <Qd>, <Dn>, <Dm>
VMLSL.<dt> <Qd>, <Dn>, <Dm>

VMLA.F32 <Qd>, <Qn>, <Qm>
VMLA.F32 <Dd>, <Dn>, <Dm>
VMLS.F32 <Qd>, <Qn>, <Qm>
VMLS.F32 <Dd>, <Dn>, <Dm>

//VMLA<c>.F64 <Dd>, <Dn>, <Dm>
//VMLA<c>.F32 <Sd>, <Sn>, <Sm>
//VMLS<c>.F64 <Dd>, <Dn>, <Dm>
//VMLS<c>.F32 <Sd>, <Sn>, <Sm>

VMLA.I16 <Qd>, <Qn>, D<imm3>[<imm2>]
VMLA.I16 <Dd>, <Dn>, D<imm3>[<imm2>]
VMLS.I16 <Qd>, <Qn>, D<imm3>[<imm2>]
VMLS.I16 <Dd>, <Dn>, D<imm3>[<imm2>]
#dt: I32/F32
VMLA.<dt> <Qd>, <Qn>, D<imm4>[<imm1>]
VMLA.<dt> <Dd>, <Dn>, D<imm4>[<imm1>]
VMLS.<dt> <Qd>, <Qn>, D<imm4>[<imm1>]
VMLS.<dt> <Dd>, <Dn>, D<imm4>[<imm1>]

#dt: S16/U16
VMLAL.<dt> <Qd>, <Dn>, D<imm3>[<imm2>]
VMLSL.<dt> <Qd>, <Dn>, D<imm3>[<imm2>]
#dt: S32/U32
VMLAL.<dt> <Qd>, <Dn>, D<imm4>[<imm1>]
VMLSL.<dt> <Qd>, <Dn>, D<imm4>[<imm1>]

#dt: I8/I16/I32/I64/F32
VMOV.<dt> <Qd>, #<mimm>
VMOV.<dt> <Dd>, #<mimm>

//VMOV<c>.F64 <Dd>, #<imm>
//VMOV<c>.F32 <Sd>, #<imm>

VMOV <Qd>, <Qm>
VMOV <Dd>, <Dm>

//VMOV<c>.F64 <Dd>, <Dm>
//VMOV<c>.F32 <Sd>, <Sm>

VMOV<c>.8  <Dd>[<imm3>], <Rt>
VMOV<c>.16 <Dd>[<imm2>], <Rt>
VMOV<c>.32 <Dd>[<imm1>], <Rt>

#dt: S8/U8
VMOV<c>.<dt> <Rt>, <Dn>[<imm3>]
#dt: S16/U16
VMOV<c>.<dt> <Rt>, <Dn>[<imm2>]
VMOV<c>.32 <Rt>, <Dn>[<imm1>]

//VMOV<c> <Sn>, <Rt>
//VMOV<c> <Rt>, <Sn>

VMOV<c> <Sm>, <Sm1>, <Rt>, <Rt2>
VMOV<c> <Rt>, <Rt2@D>, <Sm>, <Sm1>

VMOV<c> <Dm>, <Rt>, <Rt2>
VMOV<c> <Rt>, <Rt2@D>, <Dm>

#dt: S8/S16/S32/U8/U16/U32
VMOVL.<dt> <Qd>, <Dm>

#dt: I16/I32/I64
VMOVN.<dt> <Dd>, <Qm>

VMRS<c> <Rt>, FPSCR

VMSR<c> FPSCR, <Rt>

#dt: I8/I16/I32/P8
VMUL.<dt> <Qd>, <Qn>, <Qm>
VMUL.<dt> <Dd>, <Dn>, <Dm>

#dt: S8/S16/S32/U8/U16/U32/P8
VMULL.<dt> <Qd>, <Dn>, <Dm>

VMUL.F32 <Qd>, <Qn>, <Qm>
VMUL.F32 <Dd>, <Dn>, <Dm>

//VMUL<c>.F64 <Dd>, <Dn>, <Dm>
//VMUL<c>.F32 <Sd>, <Sn>, <Sm>

VMUL.I16 <Qd>, <Qn>, D<imm3>[<imm2>]
VMUL.I16 <Dd>, <Dn>, D<imm3>[<imm2>]
#dt: I32/F32
VMUL.<dt> <Qd>, <Qn>, D<imm4>[<imm1>]
VMUL.<dt> <Dd>, <Dn>, D<imm4>[<imm1>]

#dt: S16/U16
VMULL.<dt> <Qd>, <Dn>, D<imm3>[<imm2>]
#dt: S32/U32
VMULL.<dt> <Qd>, <Dn>, D<imm4>[<imm1>]

#dt: I16/I32
VMVN.<dt> <Qd>, #<mimm>
VMVN.<dt> <Dd>, #<mimm>

VMVN <Qd>, <Qm>
VMVN <Dd>, <Dm>

#dt: S8/S16/S32/F32
VNEG.<dt> <Qd>, <Qm>
VNEG.<dt> <Dd>, <Dm>

//VNEG<c>.F64 <Dd>, <Dm>
//VNEG<c>.F32 <Sd>, <Sm>

//VNMLA<c>.F64 <Dd>, <Dn>, <Dm>
//VNMLA<c>.F32 <Sd>, <Sn>, <Sm>
//VNMLS<c>.F64 <Dd>, <Dn>, <Dm>
//VNMLS<c>.F32 <Sd>, <Sn>, <Sm>

//VNMUL<c>.F64 <Dd>, <Dn>, <Dm>
//VNMUL<c>.F32 <Sd>, <Sn>, <Sm>

VORN <Qd>, <Qn>, <Qm>
VORN <Dd>, <Dn>, <Dm>

#dt: I16/I32
VORR.<dt> <Qd>, #<mimm>
VORR.<dt> <Dd>, #<mimm>

VORR <Qd>, <Qn>, <Qm>
VORR <Dd>, <Dn>, <Dm>

#dt: S8/S16/S32/U8/U16/U32
VPADAL.<dt> <Qd>, <Qm>
VPADAL.<dt> <Dd>, <Dm>

#dt: I8/I16/I32
VPADD.<dt> <Dd>, <Dn>, <Dm>

VPADD.F32 <Dd>, <Dn>, <Dm>
 
#dt: S8/S16/S32/U8/U16/U32
VPADDL.<dt> <Qd>, <Qm>
VPADDL.<dt> <Dd>, <Dm>

#dt: S8/S16/S32/U8/U16/U32
VPMAX.<dt> <Dd>, <Dn>, <Dm>
VPMIN.<dt> <Dd>, <Dn>, <Dm>

VPMAX.F32 <Dd>, <Dn>, <Dm>
VPMIN.F32 <Dd>, <Dn>, <Dm>

//VPOP<c>.64 <list>

//VPOP<c>.32 <list>

//VPUSH<c>.64 <list>

//VPUSH<c>.32 <list>

#dt: S8/S16/S32
VQABS.<dt> <Qd>,<Qm>
VQABS.<dt> <Dd>,<Dm>

#dt: S8/S16/S32/S64/U8/U16/U32/U64
VQADD.<dt> <Qd>,<Qn>,<Qm>
VQADD.<dt> <Dd>,<Dn>,<Dm>

#dt: S16/S32
VQDMLAL.<dt> <Qd>,<Dn>,<Dm>
VQDMLSL.<dt> <Qd>,<Dn>,<Dm>

VQDMLAL.S16 <Qd>,<Dn>,D<imm3>[<imm2>]
VQDMLSL.S16 <Qd>,<Dn>,D<imm3>[<imm2>]
VQDMLAL.S32 <Qd>,<Dn>,D<imm4>[<imm1>]
VQDMLSL.S32 <Qd>,<Dn>,D<imm4>[<imm1>]

#dt: S16/S32
VQDMULH.<dt> <Qd>,<Qn>,<Qm>
VQDMULH.<dt> <Dd>,<Dn>,<Dm>

VQDMULH.S16 <Qd>,<Qn>,D<imm3>[<imm2>]
VQDMULH.S16 <Dd>,<Dn>,D<imm3>[<imm2>]
VQDMULH.S32 <Qd>,<Qn>,D<imm4>[<imm1>]
VQDMULH.S32 <Dd>,<Dn>,D<imm4>[<imm1>]

#dt: S16/S32
VQDMULL.<dt> <Qd>,<Dn>,<Dm>

VQDMULL.S16 <Qd>,<Dn>,D<imm3>[<imm2>]
VQDMULL.S32 <Qd>,<Dn>,D<imm4>[<imm1>]

#dt: S16/S32/S64/U16/U32/U64
VQMOVN.<dt> <Dd>, <Qm>

#dt: S16/S32/S64
VQMOVUN.<dt> <Dd>, <Qm>

#dt: S8/S16/S32
VQNEG.<dt> <Qd>,<Qm>
VQNEG.<dt> <Dd>,<Dm>

#dt: S16/S32
VQRDMULH.<dt> <Qd>,<Qn>,<Qm>
VQRDMULH.<dt> <Dd>,<Dn>,<Dm>

VQRDMULH.S16 <Qd>,<Qn>,D<imm3>[<imm2>]
VQRDMULH.S16 <Dd>,<Dn>,D<imm3>[<imm2>]
VQRDMULH.S32 <Qd>,<Qn>,D<imm4>[<imm1>]
VQRDMULH.S32 <Dd>,<Dn>,D<imm4>[<imm1>]

#dt: S8/S16/S32/S64/U8/U16/U32/U64
VQRSHL.<dt> <Qd>,<Qm>,<Qn>
VQRSHL.<dt> <Dd>,<Dm>,<Dn>

#dt: S16/U16
VQRSHRN.<dt> <Dd>,<Qm>,#<imm3>+1

#dt: S32/U32
VQRSHRN.<dt> <Dd>,<Qm>,#<imm4>+1

#dt: S64/U64
VQRSHRN.<dt> <Dd>,<Qm>,#<imm5>+1

VQRSHRUN.S16 <Dd>,<Qm>,#<imm3>+1
VQRSHRUN.S32 <Dd>,<Qm>,#<imm4>+1
VQRSHRUN.S64 <Dd>,<Qm>,#<imm5>+1

#dt: S8/S16/S32/S64/U8/U16/U32/U64
VQSHL.<dt> <Qd>,<Qm>,<Qn>
VQSHL.<dt> <Dd>,<Dm>,<Dn>

#dt: S8/U8
VQSHL.<dt> <Qd>,<Qm>,#<imm3>
VQSHL.<dt> <Dd>,<Dm>,#<imm3>
#dt: S16/U16
VQSHL.<dt> <Qd>,<Qm>,#<imm4>
VQSHL.<dt> <Dd>,<Dm>,#<imm4>
#dt: S32/U32
VQSHL.<dt> <Qd>,<Qm>,#<imm5>
VQSHL.<dt> <Dd>,<Dm>,#<imm5>
#dt: S64/U64
VQSHL.<dt> <Qd>,<Qm>,#<imm6>
VQSHL.<dt> <Dd>,<Dm>,#<imm6>

VQSHLU.S8 <Qd>,<Qm>,#<imm3>
VQSHLU.S8 <Dd>,<Dm>,#<imm3>
VQSHLU.S16 <Qd>,<Qm>,#<imm4>
VQSHLU.S16 <Dd>,<Dm>,#<imm4>
VQSHLU.S32 <Qd>,<Qm>,#<imm5>
VQSHLU.S32 <Dd>,<Dm>,#<imm5>
VQSHLU.S64 <Qd>,<Qm>,#<imm6>
VQSHLU.S64 <Dd>,<Dm>,#<imm6>

#dt: S16/U16
VQSHRN.<dt> <Dd>,<Qm>,#<imm3>+1
#dt: S32/U32
VQSHRN.<dt> <Dd>,<Qm>,#<imm4>+1
#dt: S64/U64
VQSHRN.<dt> <Dd>,<Qm>,#<imm5>+1

VQSHRUN.S16 <Dd>,<Qm>,#<imm3>+1
VQSHRUN.S32 <Dd>,<Qm>,#<imm4>+1
VQSHRUN.S64 <Dd>,<Qm>,#<imm5>+1

#dt: S8/S16/S32/S64/U8/U16/U32/U64
VQSUB.<dt> <Qd>, <Qn>, <Qm>
VQSUB.<dt> <Dd>, <Dn>, <Dm>

#dt: I16/I32/I64
VRADDHN.<dt> <Dd>, <Qn>, <Qm>

#dt: U32/F32
VRECPE.<dt> <Qd>, <Qm>
VRECPE.<dt> <Dd>, <Dm>

VRECPS.F32 <Qd>, <Qn>, <Qm>
VRECPS.F32 <Dd>, <Dn>, <Dm>

VREV16.8 <Qd>, <Qm>
VREV16.8 <Dd>, <Dm>

#size: 8/16
VREV32.<size> <Qd>, <Qm>
VREV32.<size> <Dd>, <Dm>

#size: 8/16/32
VREV64.<size> <Qd>, <Qm>
VREV64.<size> <Dd>, <Dm>

#dt: S8/S16/S32/U8/U16/U32
VRHADD.<dt> <Qd>, <Qn>, <Qm>
VRHADD.<dt> <Dd>, <Dn>, <Dm>

VRSHL.<dt> <Qd>, <Qm>, <Qn>
VRSHL.<dt> <Dd>, <Dm>, <Dn>

#dt: S8/U8
VRSHR.<dt> <Qd>, <Qm>, #<imm3>+1
VRSHR.<dt> <Dd>, <Dm>, #<imm3>+1
#dt: S16/U16
VRSHR.<dt> <Qd>, <Qm>, #<imm4>+1
VRSHR.<dt> <Dd>, <Dm>, #<imm4>+1
#dt: S32/U32
VRSHR.<dt> <Qd>, <Qm>, #<imm5>+1
VRSHR.<dt> <Dd>, <Dm>, #<imm5>+1
#dt: S64/U64
VRSHR.<dt> <Qd>, <Qm>, #<imm6>+1
VRSHR.<dt> <Dd>, <Dm>, #<imm6>+1

VRSHRN.I16 <Dd>, <Qm>, #<imm3>+1
VRSHRN.I32 <Dd>, <Qm>, #<imm4>+1
VRSHRN.I64 <Dd>, <Qm>, #<imm5>+1

#dt: U32/F32
VRSQRTE.<dt> <Qd>, <Qm>
VRSQRTE.<dt> <Dd>, <Dm>

VRSQRTS.F32 <Qd>, <Qn>, <Qm>
VRSQRTS.F32 <Dd>, <Dn>, <Dm>

#dt: S8/U8
VRSRA.<dt> <Qd>, <Qm>, #<imm3>+1
VRSRA.<dt> <Dd>, <Dm>, #<imm3>+1
#dt: S16/U16
VRSRA.<dt> <Qd>, <Qm>, #<imm4>+1
VRSRA.<dt> <Dd>, <Dm>, #<imm4>+1
#dt: S32/U32
VRSRA.<dt> <Qd>, <Qm>, #<imm5>+1
VRSRA.<dt> <Dd>, <Dm>, #<imm5>+1
#dt: S64/U64
VRSRA.<dt> <Qd>, <Qm>, #<imm6>+1
VRSRA.<dt> <Dd>, <Dm>, #<imm6>+1

#dt: I16/I32/I64
VRSUBHN.<dt> <Dd>, <Qn>, <Qm>

VSHL.I8 <Qd>, <Qm>, #<imm3>
VSHL.I8 <Dd>, <Dm>, #<imm3>
VSHL.I16 <Qd>, <Qm>, #<imm4>
VSHL.I16 <Dd>, <Dm>, #<imm4>
VSHL.I32 <Qd>, <Qm>, #<imm5>
VSHL.I32 <Dd>, <Dm>, #<imm5>
VSHL.I64 <Qd>, <Qm>, #<imm6>
VSHL.I64 <Dd>, <Dm>, #<imm6>

#dt: U8/U16/U32/U64/S8/S16/S32/S64
VSHL.<dt> <Qd>, <Qm>, <Qn>
VSHL.<dt> <Dd>, <Dm>, <Dn>

#dt: S8/U8
VSHLL.<dt> <Qd>, <Dm>, #<imm3>
#dt: S16/U16
VSHLL.<dt> <Qd>, <Dm>, #<imm4>
#dt: S32/U32
VSHLL.<dt> <Qd>, <Dm>, #<imm5>

#size: 8/16/32
VSHLL.I<size> <Qd>, <Dm>, #<size>

#dt: S8/U8
VSHR.<dt> <Qd>, <Qm>, #<imm3>+1
VSHR.<dt> <Dd>, <Dm>, #<imm3>+1
#dt: S16/U16
VSHR.<dt> <Qd>, <Qm>, #<imm4>+1
VSHR.<dt> <Dd>, <Dm>, #<imm4>+1
#dt: S32/U32
VSHR.<dt> <Qd>, <Qm>, #<imm5>+1
VSHR.<dt> <Dd>, <Dm>, #<imm5>+1
#dt: S64/U64
VSHR.<dt> <Qd>, <Qm>, #<imm6>+1
VSHR.<dt> <Dd>, <Dm>, #<imm6>+1

VSHRN.I16 <Dd>, <Qm>, #<imm3>+1
VSHRN.I32 <Dd>, <Qm>, #<imm4>+1
VSHRN.I64 <Dd>, <Qm>, #<imm5>+1

VSLI.8 <Qd>, <Qm>, #<imm3>
VSLI.8 <Dd>, <Dm>, #<imm3>
VSLI.16 <Qd>, <Qm>, #<imm4>
VSLI.16 <Dd>, <Dm>, #<imm4>
VSLI.32 <Qd>, <Qm>, #<imm5>
VSLI.32 <Dd>, <Dm>, #<imm5>
VSLI.64 <Qd>, <Qm>, #<imm6>
VSLI.64 <Dd>, <Dm>, #<imm6>

//VSQRT<c>.F64 <Dd>, <Dm>
//VSQRT<c>.F32 <Sd>, <Sm>

#dt: S8/U8
VSRA.<dt> <Qd>, <Qm>, #<imm3>+1
VSRA.<dt> <Dd>, <Dm>, #<imm3>+1
#dt: S16/U16
VSRA.<dt> <Qd>, <Qm>, #<imm4>+1
VSRA.<dt> <Dd>, <Dm>, #<imm4>+1
#dt: S32/U32
VSRA.<dt> <Qd>, <Qm>, #<imm5>+1
VSRA.<dt> <Dd>, <Dm>, #<imm5>+1
#dt: S64/U64
VSRA.<dt> <Qd>, <Qm>, #<imm6>+1
VSRA.<dt> <Dd>, <Dm>, #<imm6>+1

VSRI.8 <Qd>, <Qm>, #<imm3>+1
VSRI.8 <Dd>, <Dm>, #<imm3>+1
VSRI.16 <Qd>, <Qm>, #<imm4>+1
VSRI.16 <Dd>, <Dm>, #<imm4>+1
VSRI.32 <Qd>, <Qm>, #<imm5>+1
VSRI.32 <Dd>, <Dm>, #<imm5>+1
VSRI.64 <Qd>, <Qm>, #<imm6>+1
VSRI.64 <Dd>, <Dm>, #<imm6>+1

#dt: I8/I16/I32/I64
VSUB.<dt> <Qd>, <Qn>, <Qm>
VSUB.<dt> <Dd>, <Dn>, <Dm>

VSUB.F32 <Qd>, <Qn>, <Qm>
VSUB.F32 <Dd>, <Dn>, <Dm>

//VSUB<c>.F64 <Dd>, <Dn>, <Dm>
//VSUB<c>.F32 <Sd>, <Sn>, <Sm>

#dt: I16/I32/I64
VSUBHN.<dt> <Dd>, <Qn>, <Qm>

#dt: S8/S16/S32/U8/U16/U32
VSUBL.<dt> <Qd>, <Dn>, <Dm>
VSUBW.<dt> <Qd>, <Qn>, <Dm>

VSWP <Qd>, <Qm>
VSWP <Dd>, <Dm>

#list: {<Dn>}/{<Dn>,<Dn+1>}/{<Dn>,<Dn+1>,<Dn+2>}/{<Dn>,<Dn+1>,<Dn+2>,<Dn+3>}
VTBL.8 <Dd>, <Dlist>, <Dm>
VTBX.8 <Dd>, <Dlist>, <Dm>

#size: 8/16/32
VTRN.<size> <Qd>, <Qm>
VTRN.<size> <Dd>, <Dm>

#size: 8/16/32 
VTST.<size> <Qd>, <Qn>, <Qm>
VTST.<size> <Dd>, <Dn>, <Dm>

#size: 8/16/32
VUZP.<size> <Qd>, <Qm>
VUZP.<size> <Dd>, <Dm>

#size: 8/16/32
VZIP.<size> <Qd>, <Qm>
VZIP.<size> <Dd>, <Dm>

